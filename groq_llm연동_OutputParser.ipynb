{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965b93ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328c649",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9369c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'format_instructions': 'Your response should be a list of comma separated '\n",
      "                        'values, eg: `foo, bar, baz` or `foo,bar,baz`'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "pprint(prompt.partial_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5525c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\n",
      "['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Robotics']\n",
      " './data/ai_technologies.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "#model = ChatOpenAI(temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# \"AI ê´€ë ¨ ê¸°ìˆ \"ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "result = chain.invoke({\"subject\": \"AI ê´€ë ¨ ê¸°ìˆ \"})\n",
    "\n",
    "# ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(\" AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\")\n",
    "print(result)\n",
    "\n",
    "# ê²°ê³¼ í™œìš© ì˜ˆì‹œ: CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "csv_filename = \"./data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI ê¸°ìˆ \"])  # í—¤ë” ì¶”ê°€\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c749389",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daf3ecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={'format_instructions': 'Return a JSON object.'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], input_types={}, partial_variables={}, template='#Format: {format_instructions}\\n\\n#Question: {question}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a199f369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤\",\n",
      "        \"goal\": \"ëª…ì™•ì„± íƒì‚¬\",\n",
      "        \"agency\": \"NASA\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì¹´ì‹œë‹ˆ-í˜¸ì´ê²ìŠ¤\",\n",
      "        \"goal\": \"í† ì„±ì˜ ìœ„ì„± íƒ€ì´íƒ„ íƒì‚¬\",\n",
      "        \"agency\": \"NASA, ESA, ì´íƒˆë¦¬ì•„ ìš°ì£¼êµ­\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸\",\n",
      "        \"goal\": \"ë‹¬ì˜ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ ìš°ì£¼êµ­\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166c3f8",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1787617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Format Instructions:\n",
      " The output should be formatted as a string as the operation, followed by a colon, followed by the column or row to be queried on, followed by optional array parameters.\n",
      "1. The column names are limited to the possible columns below.\n",
      "2. Arrays must either be a comma-separated list of numbers formatted as [1,3,5], or it must be in range of numbers formatted as [0..4].\n",
      "3. Remember that arrays are optional and not necessarily required.\n",
      "4. If the column is not in the possible columns or the operation is not a valid Pandas DataFrame operation, return why it is invalid as a sentence starting with either \"Invalid column\" or \"Invalid operation\".\n",
      "\n",
      "As an example, for the formats:\n",
      "1. String \"column:num_legs\" is a well-formatted instance which gets the column num_legs, where num_legs is a possible column.\n",
      "2. String \"row:1\" is a well-formatted instance which gets row 1.\n",
      "3. String \"column:num_legs[1,2]\" is a well-formatted instance which gets the column num_legs for rows 1 and 2, where num_legs is a possible column.\n",
      "4. String \"row:1[num_legs]\" is a well-formatted instance which gets row 1, but for just column num_legs, where num_legs is a possible column.\n",
      "5. String \"mean:num_legs[1..3]\" is a well-formatted instance which takes the mean of num_legs from rows 1 to 3, where num_legs is a possible column and mean is a valid Pandas DataFrame operation.\n",
      "6. String \"do_something:num_legs\" is a badly-formatted instance, where do_something is not a valid Pandas DataFrame operation.\n",
      "7. String \"mean:invalid_col\" is a badly-formatted instance, where invalid_col is not a possible column.\n",
      "\n",
      "Here are the possible columns:\n",
      "```\n",
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "# Titanic ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser ì„¤ì •\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "\n",
    "# í˜•ì‹ ì§€ì¹¨ ì¶œë ¥\n",
    "format_instructions = parser.get_format_instructions()\n",
    "print(\"Format Instructions:\\n\", format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f746503b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b248b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ì»¬ëŸ¼ ì¶œë ¥\n",
      "<class 'dict'>\n",
      "{'Name': 0                                 Mr. Owen Harris Braund\n",
      "1      Mrs. John Bradley (Florence Briggs Thayer) Cum...\n",
      "2                                  Miss. Laina Heikkinen\n",
      "3            Mrs. Jacques Heath (Lily May Peel) Futrelle\n",
      "4                                Mr. William Henry Allen\n",
      "                             ...                        \n",
      "882                                 Rev. Juozas Montvila\n",
      "883                          Miss. Margaret Edith Graham\n",
      "884                       Miss. Catherine Helen Johnston\n",
      "885                                 Mr. Karl Howell Behr\n",
      "886                                   Mr. Patrick Dooley\n",
      "Name: Name, Length: 887, dtype: object}\n",
      "ì²«ë²ˆì§¸ í–‰ ì¶œë ¥\n",
      "ì˜¤ë¥˜ ë°œìƒ: Unsupported request type '```\n",
      "row'.                         Please check the format instructions.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ëª¨ë¸ ì‘ë‹µ ë°›ê¸°\n",
    "try:\n",
    "    # **Name ì—´ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('Name ì»¬ëŸ¼ ì¶œë ¥')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **ì²«ë²ˆì§¸ í–‰ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('ì²«ë²ˆì§¸ í–‰ ì¶œë ¥')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1596db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"data\": string  // A list of dictionaries representing table rows.\\n}\\n```'} template='\\n    You are an AI assistant that generates tabular data. \\n    You must return the data in JSON format that follows this schema:\\n\\n    {format_instructions}\\n\\n    **User Query:**\\n    {query}\\n    '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜ {data : [{},{},{}] }\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser ì„¤ì •\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87e604c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # ëª¨ë¸ í˜¸ì¶œ\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "        print(json_response)\n",
    "        \n",
    "        # ëª¨ë¸ì´ ë°˜í™˜í•œ JSONì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\nğŸ”¹ Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed1941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
      "{'data': [{'District': 'Gangnam-gu', 'Average Price': 1500000000, 'Number of Transactions': 1200, 'Year-over-Year Change (%)': 3.5}, {'District': 'Jongno-gu', 'Average Price': 950000000, 'Number of Transactions': 800, 'Year-over-Year Change (%)': 2.1}, {'District': 'Mapo-gu', 'Average Price': 1100000000, 'Number of Transactions': 950, 'Year-over-Year Change (%)': 4.0}, {'District': 'Seocho-gu', 'Average Price': 1450000000, 'Number of Transactions': 1100, 'Year-over-Year Change (%)': 3.8}, {'District': 'Songpa-gu', 'Average Price': 1300000000, 'Number of Transactions': 1050, 'Year-over-Year Change (%)': 3.2}, {'District': 'Yongsan-gu', 'Average Price': 1250000000, 'Number of Transactions': 900, 'Year-over-Year Change (%)': 2.9}, {'District': 'Gwanak-gu', 'Average Price': 850000000, 'Number of Transactions': 700, 'Year-over-Year Change (%)': 1.5}, {'District': 'Dongdaemun-gu', 'Average Price': 800000000, 'Number of Transactions': 750, 'Year-over-Year Change (%)': 1.8}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n",
      "(8, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Average Price</th>\n",
       "      <th>Number of Transactions</th>\n",
       "      <th>Year-over-Year Change (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gangnam-gu</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>1200</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>950000000</td>\n",
       "      <td>800</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>1100000000</td>\n",
       "      <td>950</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seocho-gu</td>\n",
       "      <td>1450000000</td>\n",
       "      <td>1100</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Songpa-gu</td>\n",
       "      <td>1300000000</td>\n",
       "      <td>1050</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yongsan-gu</td>\n",
       "      <td>1250000000</td>\n",
       "      <td>900</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>850000000</td>\n",
       "      <td>700</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dongdaemun-gu</td>\n",
       "      <td>800000000</td>\n",
       "      <td>750</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        District  Average Price  Number of Transactions  \\\n",
       "0     Gangnam-gu     1500000000                    1200   \n",
       "1      Jongno-gu      950000000                     800   \n",
       "2        Mapo-gu     1100000000                     950   \n",
       "3      Seocho-gu     1450000000                    1100   \n",
       "4      Songpa-gu     1300000000                    1050   \n",
       "5     Yongsan-gu     1250000000                     900   \n",
       "6      Gwanak-gu      850000000                     700   \n",
       "7  Dongdaemun-gu      800000000                     750   \n",
       "\n",
       "   Year-over-Year Change (%)  \n",
       "0                        3.5  \n",
       "1                        2.1  \n",
       "2                        4.0  \n",
       "3                        3.8  \n",
       "4                        3.2  \n",
       "5                        2.9  \n",
       "6                        1.5  \n",
       "7                        1.8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [ì˜ˆì œ 1] 2024ë…„ ìƒë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
    "print('2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (êµ¬), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8347050c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
      "{'data': [{'Station Name': 'Gangnam', 'Line Number': 'Line 2', 'Daily Passenger Volume': 150000, 'Weekday vs Weekend Ratio': '1.2'}, {'Station Name': 'Jamsil', 'Line Number': 'Line 2', 'Daily Passenger Volume': 140000, 'Weekday vs Weekend Ratio': '1.1'}, {'Station Name': 'Seoul Station', 'Line Number': 'Line 1', 'Daily Passenger Volume': 130000, 'Weekday vs Weekend Ratio': '1.3'}, {'Station Name': 'Hongdae', 'Line Number': 'Line 2', 'Daily Passenger Volume': 125000, 'Weekday vs Weekend Ratio': '1.0'}, {'Station Name': 'Samseong', 'Line Number': 'Line 2', 'Daily Passenger Volume': 120000, 'Weekday vs Weekend Ratio': '1.2'}, {'Station Name': 'Express Bus Terminal', 'Line Number': 'Line 3', 'Daily Passenger Volume': 115000, 'Weekday vs Weekend Ratio': '1.1'}, {'Station Name': 'Yeouido', 'Line Number': 'Line 5', 'Daily Passenger Volume': 110000, 'Weekday vs Weekend Ratio': '1.4'}, {'Station Name': 'Dongdaemun', 'Line Number': 'Line 4', 'Daily Passenger Volume': 105000, 'Weekday vs Weekend Ratio': '1.2'}, {'Station Name': 'Myeongdong', 'Line Number': 'Line 4', 'Daily Passenger Volume': 100000, 'Weekday vs Weekend Ratio': '1.3'}, {'Station Name': 'City Hall', 'Line Number': 'Line 1', 'Daily Passenger Volume': 95000, 'Weekday vs Weekend Ratio': '1.1'}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°')\n",
    "# [ì˜ˆì œ 2] 2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    \"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    ")\n",
    "if df_seoul_subway is not None:\n",
    "    #print(df_seoul_subway.shape)\n",
    "    df_seoul_subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b70cc025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
      "{'data': [{'Brand Name': 'CU', 'Number of Stores': 15000, 'Total Revenue (in billion KRW)': 5000, 'Market Share (%)': 35.0}, {'Brand Name': 'GS25', 'Number of Stores': 14000, 'Total Revenue (in billion KRW)': 4800, 'Market Share (%)': 33.5}, {'Brand Name': '7-Eleven', 'Number of Stores': 10000, 'Total Revenue (in billion KRW)': 3000, 'Market Share (%)': 20.0}, {'Brand Name': 'Emart24', 'Number of Stores': 5000, 'Total Revenue (in billion KRW)': 1500, 'Market Share (%)': 7.5}, {'Brand Name': 'Ministop', 'Number of Stores': 2000, 'Total Revenue (in billion KRW)': 700, 'Market Share (%)': 4.0}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Number of Stores</th>\n",
       "      <th>Total Revenue (in billion KRW)</th>\n",
       "      <th>Market Share (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CU</td>\n",
       "      <td>15000</td>\n",
       "      <td>5000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS25</td>\n",
       "      <td>14000</td>\n",
       "      <td>4800</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>10000</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emart24</td>\n",
       "      <td>5000</td>\n",
       "      <td>1500</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ministop</td>\n",
       "      <td>2000</td>\n",
       "      <td>700</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand Name  Number of Stores  Total Revenue (in billion KRW)  \\\n",
       "0         CU             15000                            5000   \n",
       "1       GS25             14000                            4800   \n",
       "2   7-Eleven             10000                            3000   \n",
       "3    Emart24              5000                            1500   \n",
       "4   Ministop              2000                             700   \n",
       "\n",
       "   Market Share (%)  \n",
       "0              35.0  \n",
       "1              33.5  \n",
       "2              20.0  \n",
       "3               7.5  \n",
       "4               4.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜')\n",
    "# [ì˜ˆì œ 3] í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    \"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bb8f4d",
   "metadata": {},
   "source": [
    "### PydanticOutputParser "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d3a540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add pydantic\n",
    "# %pip install pydantic \n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0873520d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"movie_title\": {\"description\": \"ì¶”ì²œ ì˜í™” ì œëª©\", \"title\": \"Movie Title\", \"type\": \"string\"}, \"reason\": {\"description\": \"ì¶”ì²œ ì´ìœ \", \"title\": \"Reason\", \"type\": \"string\"}, \"genre\": {\"description\": \"ì˜í™” ì¥ë¥´\", \"items\": {\"type\": \"string\"}, \"title\": \"Genre\", \"type\": \"array\"}, \"estimated_rating\": {\"description\": \"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \", \"title\": \"Estimated Rating\", \"type\": \"number\"}}, \"required\": [\"movie_title\", \"reason\", \"genre\", \"estimated_rating\"]}\\n```'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'query'], input_types={}, partial_variables={}, template='\\në‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\\nìš”ì²­: {query}\\n\\n{format_instructions}\\n'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸\n",
    "class MovieRecommendation(BaseModel):\n",
    "    movie_title: str = Field(description=\"ì¶”ì²œ ì˜í™” ì œëª©\")\n",
    "    reason: str = Field(description=\"ì¶”ì²œ ì´ìœ \")\n",
    "    genre: List[str] = Field(description=\"ì˜í™” ì¥ë¥´\")\n",
    "    estimated_rating: float = Field(description=\"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \")\n",
    "    \n",
    "# Pydantic ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecommendation)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "ìš”ì²­: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# íŒŒì„œì˜ ì§€ì‹œì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67843f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ ì˜í™”: The Sixth Sense (1999)\n",
      "ì¶”ì²œ ì´ìœ : 1990ë…„ëŒ€ í´ë˜ì‹í•œ ëŠë‚Œì˜ ê³µí¬ ì˜í™”ë¡œ, ë°˜ì „ì˜ ë¬˜ë¯¸ê°€ ìˆëŠ” ì‘í’ˆì…ë‹ˆë‹¤.\n",
      "ì¥ë¥´: ê³µí¬, ë¯¸ìŠ¤í„°ë¦¬, ìŠ¤ë¦´ëŸ¬\n",
      "ì˜ˆìƒ í‰ì : 8.5/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "query = \"1990ë…„ëŒ€ í´ë˜ì‹í•œ ëŠë‚Œì˜ ê³µí¬ ì˜í™” ì¶”ì²œí•´ì¤˜\"\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì¶”ì²œ ì˜í™”: {output.movie_title}\")\n",
    "print(f\"ì¶”ì²œ ì´ìœ : {output.reason}\")\n",
    "print(f\"ì¥ë¥´: {', '.join(output.genre)}\")\n",
    "print(f\"ì˜ˆìƒ í‰ì : {output.estimated_rating}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f0e1c5",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb69bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"rating\": string  // 5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \n",
      "\t\"pros\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"cons\": string  // ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\n",
      "\t\"summary\": string  // ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# ì¶œë ¥ êµ¬ì¡° ì •ì˜ (í‰ì , ì¥ì , ë‹¨ì , ìš”ì•½)\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"rating\", description=\"5ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \"),\n",
    "    ResponseSchema(name=\"pros\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ì¥ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"cons\", description=\"ë¦¬ë·°ì—ì„œ ì–¸ê¸‰ëœ ë‹¨ì  3ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶œë ¥\"),\n",
    "    ResponseSchema(name=\"summary\", description=\"ë¦¬ë·°ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½\")\n",
    "]\n",
    "\n",
    "# íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(\"ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì œí’ˆ ë¦¬ë·°ë¥¼ ë¶„ì„í•˜ì„¸ìš”. ë¦¬ë·° ë‚´ìš©: {review}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21d684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ë¶„ì„ ê²°ê³¼ =====\n",
      "{'cons': ['ê°€ê²©ì´ ë¹„ì‹¸ë‹¤', 'ë¬´ê²Œê°€ ë¬´ê±°ì›Œì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆë‹¤', ' '],\n",
      " 'pros': ['ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì¢‹ë‹¤', 'ì¹´ë©”ë¼ í™”ì§ˆì´ ì„ ëª…í•˜ë‹¤', 'ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•˜ë‹¤'],\n",
      " 'rating': '4',\n",
      " 'summary': 'ìŠ¤ë§ˆíŠ¸í°ì˜ ë°°í„°ë¦¬ ìˆ˜ëª…ê³¼ ì¹´ë©”ë¼ í™”ì§ˆì´ ìš°ìˆ˜í•˜ì§€ë§Œ, ê°€ê²©ì´ ë¹„ì‹¸ê³  ë¬´ê²ë‹¤ëŠ” ë¦¬ë·°ì…ë‹ˆë‹¤.'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.5ë¡œ ì„¤ì •í•´ ì¼ê´€ì„± ìˆëŠ” ì¶œë ¥)\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë¦¬ë·° ë°ì´í„°\n",
    "review = \"\"\"\n",
    "ì´ ìŠ¤ë§ˆíŠ¸í°ì€ ë°°í„°ë¦¬ ìˆ˜ëª…ì´ ì •ë§ ì¢‹ì•„ì„œ í•˜ë£¨ ì¢…ì¼ ì‚¬ìš©í•´ë„ ì¶©ì „ì´ í•„ìš” ì—†ì—ˆì–´ìš”. \n",
    "ì¹´ë©”ë¼ í™”ì§ˆë„ ì„ ëª…í•˜ê³ , íŠ¹íˆ ì•¼ê°„ ëª¨ë“œê°€ í›Œë¥­í•©ë‹ˆë‹¤. \n",
    "ë‹¤ë§Œ ê°€ê²©ì´ ì¡°ê¸ˆ ë¹„ì‹¸ê³ , ë¬´ê²Œê°€ 200gì´ ë„˜ì–´ì„œ ì†ì´ í”¼ê³¤í•  ìˆ˜ ìˆì–´ìš”.\n",
    "\"\"\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "chain = prompt | model | parser\n",
    "\n",
    "output = chain.invoke({\"review\": review})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥ (Pretty Print)\n",
    "print(\"===== ë¶„ì„ ê²°ê³¼ =====\")\n",
    "pprint(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6263a972",
   "metadata": {},
   "source": [
    "### DatetimeOutputParser\n",
    "* pip install python-dateutil\n",
    "* poetry add python-dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34c176f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-11 14:38:48.541615\n",
      "ë‚ ì§œ ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\n",
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0838-04-03T21:56:55.369164Z, 0105-04-20T10:17:23.343889Z, 1237-09-11T15:22:40.906593Z\n",
      "\n",
      "Return ONLY this string, no other words!\n",
      "prompt = input_variables=['text'] input_types={} partial_variables={'format_instructions': \"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 0838-04-03T21:56:55.369164Z, 0105-04-20T10:17:23.343889Z, 1237-09-11T15:22:40.906593Z\\n\\nReturn ONLY this string, no other words!\"} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'text'], input_types={}, partial_variables={}, template=\"\\ní˜„ì¬ ë‚ ì§œ: 2025-06-11\\në‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ/ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ìƒëŒ€ì  í‘œí˜„(ì˜ˆ: 'ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼')ì€ í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\\ní…ìŠ¤íŠ¸: {text}\\n\\n{format_instructions}\\n\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "#%pip install python-dateutil\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(datetime.today())\n",
    "\n",
    "# ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™” (ì‹œê°„ëŒ€ í¬í•¨ ê°€ëŠ¥)\n",
    "datetime_parser = DatetimeOutputParser()\n",
    "format_instructions = datetime_parser.get_format_instructions()\n",
    "\n",
    "print(\"ë‚ ì§œ ì¶œë ¥ í˜•ì‹ ì§€ì‹œì‚¬í•­:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "# í˜„ì¬ ë‚ ì§œë¥¼ ëª…ì‹œì ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "template = f\"\"\"\n",
    "í˜„ì¬ ë‚ ì§œ: {current_date}\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ/ì‹œê°„ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. ìƒëŒ€ì  í‘œí˜„(ì˜ˆ: 'ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼')ì€ í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "í…ìŠ¤íŠ¸: {{text}}\n",
    "\n",
    "{{format_instructions}}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "\n",
    "print(f'prompt = {prompt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51af50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: íšŒì˜ëŠ” 2025ë…„ 6ì›” 15ì¼ ì˜¤í›„ 2ì‹œì— ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-15 14:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì…ë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-20 00:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: í–‰ì‚¬ ì‹œì‘: 7/25/2025 18:00 KST\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-07-25 18:00:00 \n",
      "\n",
      "ì›ë³¸ í…ìŠ¤íŠ¸: 3ì¼ í›„ì— ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "ì¶”ì¶œëœ ë‚ ì§œ: 2025-06-14 00:00:00 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” (temperature=0.1ë¡œ ì„¤ì •í•´ ì •í™•í•œ ë‚ ì§œ ì¶œë ¥ ê°•ì¡°)\n",
    "#model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ í¬í•¨)\n",
    "texts = [\n",
    "    \"íšŒì˜ëŠ” 2025ë…„ 6ì›” 15ì¼ ì˜¤í›„ 2ì‹œì— ì˜ˆì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"í”„ë¡œì íŠ¸ ë§ˆê°ì¼ì€ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì…ë‹ˆë‹¤.\",\n",
    "    \"í–‰ì‚¬ ì‹œì‘: 7/25/2025 18:00 KST\",\n",
    "    \"3ì¼ í›„ì— ì‹œìŠ¤í…œ ì ê²€ì´ ì§„í–‰ë©ë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥\n",
    "chain = prompt | model | datetime_parser\n",
    "\n",
    "for text in texts:\n",
    "    print(f\"\\nì›ë³¸ í…ìŠ¤íŠ¸: {text}\")\n",
    "    output = chain.invoke({\"text\": text})\n",
    "    print(f\"ì¶”ì¶œëœ ë‚ ì§œ: {output.strftime('%Y-%m-%d %H:%M:%S %Z')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f092e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ë‚ ì§œ: 2025-06-11\n",
      "\n",
      "í…ìŠ¤íŠ¸ì—ì„œ ì´ë²¤íŠ¸ ë‚ ì§œë¥¼ ì¶”ì¶œí•˜ê³  í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“\n",
      "- ë‚ ì§œ: 2025-12-10 00:00:00\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°\n",
      "- ë‚ ì§œ: 2025-12-24 00:00:00\n",
      "\n",
      "- ì´ë²¤íŠ¸ëª…: ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´\n",
      "- ë‚ ì§œ: 2026-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "# ì´ë²¤íŠ¸ ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "event_template = \"\"\"\n",
    "í˜„ì¬ ë‚ ì§œ: {current_date}\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ëª¨ë“  ì´ë²¤íŠ¸ì˜ ë‚ ì§œ/ì‹œê°„ì„ ì¶”ì¶œí•˜ì„¸ìš”. ê° ì´ë²¤íŠ¸ëŠ” ì´ë¦„ê³¼ ë‚ ì§œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "ê° ì´ë²¤íŠ¸ì˜ ë‚ ì§œëŠ” í˜„ì¬ ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "í…ìŠ¤íŠ¸: {text}\n",
    "\n",
    "ì¶œë ¥ í˜•ì‹:\n",
    "- ì´ë²¤íŠ¸ëª…: [ì´ë¦„]\n",
    "- ë‚ ì§œ: [YYYY-MM-DD HH:MM:SS]\n",
    "\"\"\"\n",
    "\n",
    "event_prompt = ChatPromptTemplate.from_template(event_template)\n",
    "event_chain = event_prompt | model\n",
    "\n",
    "# ì˜ˆì‹œ í…ìŠ¤íŠ¸ (ì—¬ëŸ¬ ì´ë²¤íŠ¸ í¬í•¨)\n",
    "event_text = \"\"\"\n",
    "12ì›” 10ì¼ì— í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ë§ˆì¼“ì´ ì—´ë¦¬ê³ , 12ì›” 24ì¼ì—ëŠ” í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ì´ë¸Œ íŒŒí‹°ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "ë˜í•œ ë‚´ë…„ 1ì›” 1ì¼ 00:00ì— ìƒˆí•´ ì¹´ìš´íŠ¸ë‹¤ìš´ì´ ì§„í–‰ë  ì˜ˆì •ì…ë‹ˆë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "print(event_chain.invoke({\"current_date\":current_date, \"text\": event_text}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16882a47",
   "metadata": {},
   "source": [
    "### EnumOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a516873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\n",
      "Select one of the following options: ê¸ì •, ë¶€ì •, ì¤‘ë¦½\n",
      "input_variables=['text'] input_types={} partial_variables={'format_instructions': 'Select one of the following options: ê¸ì •, ë¶€ì •, ì¤‘ë¦½'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'text'], input_types={}, partial_variables={}, template='\\në‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\\në‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\\n\\ní…ìŠ¤íŠ¸: \"{text}\"\\n\\n{format_instructions}\\n\\nì¤‘ìš” ê·œì¹™:\\n1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\\n2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\\n3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\\n4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\\n\\në‹µë³€:'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import EnumOutputParser, OutputFixingParser\n",
    "from langchain.schema import OutputParserException\n",
    "\n",
    "from enum import Enum\n",
    "from pprint import pprint\n",
    "\n",
    "# ê°ì • í´ë˜ìŠ¤ ì •ì˜ (Enum)\n",
    "class Sentiment(str, Enum):\n",
    "    POSITIVE = \"ê¸ì •\"\n",
    "    NEGATIVE = \"ë¶€ì •\"\n",
    "    NEUTRAL = \"ì¤‘ë¦½\"\n",
    "\n",
    "# EnumOutputParser ì´ˆê¸°í™”\n",
    "enumParser = EnumOutputParser(enum=Sentiment)\n",
    "format_instructions = enumParser.get_format_instructions()\n",
    "\n",
    "print(\"ê°ì • ë¶„ë¥˜ ì¶œë ¥ í˜•ì‹:\")\n",
    "print(format_instructions)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "template = \"\"\"\n",
    "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³ , ë°˜ë“œì‹œ ì•„ë˜ ì„¸ ê°€ì§€ ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "í…ìŠ¤íŠ¸: \"{text}\"\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "ì¤‘ìš” ê·œì¹™:\n",
    "1. ë°˜ë“œì‹œ \"ê¸ì •\", \"ë¶€ì •\", \"ì¤‘ë¦½\" ì¤‘ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "2. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¶€ê°€ ì„¤ëª…ì„ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”\n",
    "3. ì´ëª¨ì§€ë‚˜ íŠ¹ìˆ˜ë¬¸ìë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”\n",
    "4. ì˜¤ì§ í•˜ë‚˜ì˜ ë‹¨ì–´ë§Œ ì¶œë ¥í•˜ì„¸ìš”\n",
    "\n",
    "ë‹µë³€:\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(format_instructions=format_instructions)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92044d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\n",
      "í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ 7ê°œ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0  # ì¼ê´€ì„±ì„ ìœ„í•´ 0ìœ¼ë¡œ ì„¤ì •\n",
    ")\n",
    "\n",
    "# OutputFixingParserë¡œ ì•ˆì •ì„± í–¥ìƒ\n",
    "fixing_parser = OutputFixingParser.from_llm(parser=enumParser, llm=model)\n",
    "\n",
    "print(\"ëª¨ë¸ ë° íŒŒì„œ ì„¤ì • ì™„ë£Œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ í…ìŠ¤íŠ¸\n",
    "texts = [\n",
    "    \"ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.\",\n",
    "    \"ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ì˜¤ëŠ˜ì€ ë¹„ê°€ ì˜¨ë‹¤ë„¤ìš”.\",\n",
    "    \"ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.\",\n",
    "    \"ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!\",\n",
    "    \"ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”\",\n",
    "    \"ì¼ì´ ë§ì•„ì„œ ë°¤ìƒ˜ì„ í–ˆì–´ìš”.\"\n",
    "]\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸ {len(texts)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4814cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\n",
      "\n",
      "1. í…ìŠ¤íŠ¸: ì´ ì œí’ˆ ì •ë§ ì¢‹ì•„ìš”! ì™„ì „ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”.\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "2. í…ìŠ¤íŠ¸: ì„œë¹„ìŠ¤ê°€ ë„ˆë¬´ ëŠë¦¬ê³  ë¶ˆì¹œì ˆí–ˆìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "3. í…ìŠ¤íŠ¸: ì˜¤ëŠ˜ì€ ë¹„ê°€ ì˜¨ë‹¤ë„¤ìš”.\n",
      "   ê°ì •: ì¤‘ë¦½ \n",
      "\n",
      "4. í…ìŠ¤íŠ¸: ë°°ì†¡ì€ ë¹ ë¥´ì§€ë§Œ í’ˆì§ˆì´ ì•„ì‰½ìŠµë‹ˆë‹¤.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "5. í…ìŠ¤íŠ¸: ìµœê³ ì˜ ê²½í—˜ì´ì—ˆìŠµë‹ˆë‹¤!\n",
      "   ê°ì •: ê¸ì • \n",
      "\n",
      "6. í…ìŠ¤íŠ¸: ì™„ì „ ì‹¤ë§í–ˆì–´ìš”... ìµœì•…ì´ì—ìš”\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "7. í…ìŠ¤íŠ¸: ì¼ì´ ë§ì•„ì„œ ë°¤ìƒ˜ì„ í–ˆì–´ìš”.\n",
      "   ê°ì •: ë¶€ì • \n",
      "\n",
      "=== ê²°ê³¼ ìš”ì•½ ===\n",
      "ì„±ê³µ: 7/7 (100.0%)\n",
      "ì‹¤íŒ¨: 0/7\n"
     ]
    }
   ],
   "source": [
    "# ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)\n",
    "def safe_sentiment_analysis(text, use_fixing_parser=True):\n",
    "    \"\"\"ì•ˆì „í•œ ê°ì • ë¶„ì„ í•¨ìˆ˜ - ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨\"\"\"\n",
    "    try:\n",
    "        # ê¸°ë³¸ ì²´ì¸ ìƒì„±\n",
    "        chain = prompt | model | (fixing_parser if use_fixing_parser else enumParser)\n",
    "        \n",
    "        # ë¶„ì„ ì‹¤í–‰\n",
    "        result = chain.invoke({\"text\": text})\n",
    "        return result, None\n",
    "        \n",
    "    except OutputParserException as e:\n",
    "        return None, f\"íŒŒì‹± ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "    except Exception as e:\n",
    "        return None, f\"ì¼ë°˜ ì˜¤ë¥˜: {str(e)[:100]}...\"\n",
    "\n",
    "# ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰ (API í‚¤ í•„ìš”)\n",
    "def run_sentiment_analysis():\n",
    "    \"\"\"ì‹¤ì œ ê°ì • ë¶„ì„ ì‹¤í–‰\"\"\"\n",
    "    print(\"=== ì‹¤ì œ ê°ì • ë¶„ì„ ê²°ê³¼ ===\")\n",
    "    \n",
    "    success_count = 0\n",
    "    total_count = len(texts)\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\n{i}. í…ìŠ¤íŠ¸: {text}\")\n",
    "        \n",
    "        # OutputFixingParser ì‚¬ìš©\n",
    "        result, error = safe_sentiment_analysis(text, use_fixing_parser=True)\n",
    "        \n",
    "        if result:\n",
    "            print(f\"   ê°ì •: {result.value} \")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"   ì˜¤ë¥˜: {error} \")\n",
    "            \n",
    "            # ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„\n",
    "            print(\"   ê¸°ë³¸ íŒŒì„œë¡œ ì¬ì‹œë„...\")\n",
    "            result2, error2 = safe_sentiment_analysis(text, use_fixing_parser=False)\n",
    "            \n",
    "            if result2:\n",
    "                print(f\"   ê°ì •: {result2.value} (ê¸°ë³¸ íŒŒì„œ ì„±ê³µ)\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"   ì¬ì‹œë„ ì‹¤íŒ¨: {error2} \")\n",
    "    \n",
    "    print(f\"\\n=== ê²°ê³¼ ìš”ì•½ ===\")\n",
    "    print(f\"ì„±ê³µ: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)\")\n",
    "    print(f\"ì‹¤íŒ¨: {total_count-success_count}/{total_count}\")\n",
    "\n",
    "# ì‹¤ì œ ë¶„ì„ ì‹¤í–‰ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°)\n",
    "try:\n",
    "    run_sentiment_analysis()\n",
    "except Exception as e:\n",
    "    print(\"API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜:\")\n",
    "    print(\"ì‹¤ì œ ì‹¤í–‰ì„ ìœ„í•´ì„œëŠ” OpenAI API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.\")\n",
    "    print(f\"ì˜¤ë¥˜ ìƒì„¸: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
