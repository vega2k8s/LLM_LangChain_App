{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744867b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama is running\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-basic-kGdHTiMZ-py3.12\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"http://127.0.0.1:11434\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9eda8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "('<think>\\n'\n",
      " 'Alright, so I need to figure out what LangChain is. The user already '\n",
      " 'provided a pretty comprehensive breakdown, but maybe I can think through it '\n",
      " 'step by step.\\n'\n",
      " '\\n'\n",
      " \"First, I know that LangChain stands for Language Generation Chain. It's part \"\n",
      " 'of the LangChain framework, which is used for generating text. But how '\n",
      " 'exactly does it work? I remember something about transformers being involved '\n",
      " 'in this process.\\n'\n",
      " '\\n'\n",
      " 'So, transformers are a big thing in NLP, right? They help with tasks like '\n",
      " 'language modeling, attention mechanisms, and classification. In the context '\n",
      " \"of LangChain, maybe they're used for generating coherent responses or \"\n",
      " 'instructions.\\n'\n",
      " '\\n'\n",
      " \"But wait, isn't there more to it than just the model itself? I think the \"\n",
      " 'model needs specific parameters. Maybe something about temperature and '\n",
      " 'top-k? Those are common hyperparameters in models like GPT-3. So if someone '\n",
      " 'wants to set a temperature of 0.5 and only get the top 10 most probable '\n",
      " 'responses, they need to configure the model accordingly.\\n'\n",
      " '\\n'\n",
      " 'Also, how does it handle context? I guess it looks at the surrounding text '\n",
      " 'to generate more meaningful answers. That makes sense because context can '\n",
      " 'provide better depth and coherence in responses.\\n'\n",
      " '\\n'\n",
      " 'I wonder about evaluation. How do you measure the quality of a LangChain '\n",
      " 'response? Maybe through metrics like BLEU or ROUGE if the model is used for '\n",
      " \"translation or summarization tasks. But for general purposes, it's often \"\n",
      " 'just how well it produces the desired text.\\n'\n",
      " '\\n'\n",
      " \"Another point: it's an open framework. That means different people can build \"\n",
      " 'upon it with custom modules and models. It encourages experimentation '\n",
      " 'without strict guidelines, which can lead to innovation but also requires '\n",
      " 'careful setup.\\n'\n",
      " '\\n'\n",
      " 'I should consider how LangChain compares to other NLP tools like ChatGPT or '\n",
      " \"OpenAI's API. While similar in the goal of generating responses, the \"\n",
      " 'specifics differ, especially in terms of integration with various platforms '\n",
      " 'or custom components.\\n'\n",
      " '\\n'\n",
      " 'What about user training? If someone uses LangChain, do they need additional '\n",
      " \"training? Probably, as it's built on top of models that require parameter \"\n",
      " 'tuning and understanding of context.\\n'\n",
      " '\\n'\n",
      " 'In summary, LangChain is a framework for text generation using '\n",
      " 'transformer-based models. It involves configuring the model with parameters '\n",
      " 'like temperature and top-k, allowing it to generate responses based on '\n",
      " \"context. It's widely used across various applications, but its effectiveness \"\n",
      " 'depends on the specific use case and customization.\\n'\n",
      " '</think>\\n'\n",
      " '\\n'\n",
      " 'LangChain, also known as the Language Generation Chain, is a comprehensive '\n",
      " 'framework designed for text generation using transformer-based models. '\n",
      " \"Here's an organized summary of its key components and features:\\n\"\n",
      " '\\n'\n",
      " '1. **Concept**: LangChain operates on the transformer architecture, which '\n",
      " 'excels in natural language processing tasks such as language modeling, '\n",
      " 'attention mechanisms, and classification.\\n'\n",
      " '\\n'\n",
      " '2. **Model Configuration**: \\n'\n",
      " '   - **Temperature**: Controls the diversity of responses by adjusting how '\n",
      " 'certain outputs are weighted.\\n'\n",
      " '   - **Top-k**: Limiting the number of most probable responses generated.\\n'\n",
      " '\\n'\n",
      " '3. **Context Handling**: Language models in LangChain analyze surrounding '\n",
      " 'text to produce more meaningful and coherent responses, enhancing depth and '\n",
      " 'context.\\n'\n",
      " '\\n'\n",
      " '4. **Evaluation Metrics**: While effectiveness depends on specific use '\n",
      " 'cases, common metrics like BLEU or ROUGE can assess translation quality. For '\n",
      " 'general purposes, response clarity is key.\\n'\n",
      " '\\n'\n",
      " \"5. **Open Framework**: LangChain's open architecture allows customization \"\n",
      " 'through module integration, fostering innovation without strict guidelines, '\n",
      " 'encouraging experimentation.\\n'\n",
      " '\\n'\n",
      " \"6. **Comparison with Other Tools**: Similar to ChatGPT and OpenAI's API but \"\n",
      " 'diverges in model specifics and context handling. Integration varies across '\n",
      " 'platforms or custom components.\\n'\n",
      " '\\n'\n",
      " '7. **Training Needs**: Requires parameter tuning and understanding of '\n",
      " 'context for effective use.\\n'\n",
      " '\\n'\n",
      " '8. **User Training**: Users need additional training, as it involves '\n",
      " 'mastering transformer configurations and context awareness.\\n'\n",
      " '\\n'\n",
      " 'In essence, LangChain is a versatile framework enabling text generation '\n",
      " 'through transformers, widely applicable in various applications but '\n",
      " 'requiring careful setup and customization.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pprint import pprint\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 deepseek-r1:1.5b 모델 로드\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"What is LangChain?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(type(response))\n",
    "pprint(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0860666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬 (Python)은 뛰어난 편의성과 활용도를 갖춘 개방형 프로그래밍 언어입니다. 이는 다음과 같은 특징을 가지고 있습니다:\n",
      "\n",
      "1. 단순하고 직관적인 문법:\n",
      "   - 3가지의 구문(예: if, def, while)\n",
      "   - 한 줄로 여러 표현 가능\n",
      "   - 객체 지향 프로그래밍과 함수형 프로그래밍 기능\n",
      "\n",
      "2. 깁스 캐싱 (Duck Typing):\n",
      "   - 타입 확인 없이 사용 가능 (type checking 생략)\n",
      "\n",
      "3. 빠른 실행시간:\n",
      "   - JIT 컴파일 언어\n",
      "   - 대용량 데이터 처리 효율적\n",
      "\n",
      "4. 다양한 기능 제공:\n",
      "   - 시스템 프로비저우, 쿼리 엔진, 웹 라우터 등\n",
      "\n",
      "5. 키보드 입력 단축키 사용 가능 (Ctrl + C: 중지)\n",
      "\n",
      "6. 설치 및 배포 간단\n",
      "7. 네트워크 상호작용이 용도를 제한하지 않음\n",
      "\n",
      "8. 무료로 다운받을 수 있는 오픈소스 프로그램\n",
      "\n",
      "파이썬은 대형 웹 브라우저 크롬과 같은 도구에서도 사용되어, 편리성을 제공합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Ollama를 사용하여 로컬에서 실행 중인 qwen2.5:1.5b 모델 로드\n",
    "llm = ChatOllama(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "# 더 정확한 응답을 위한 개선된 프롬프트\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an AI assistant that provides accurate and detailed answers.\"),\n",
    "    (\"human\", \"Q: {question}\\nA:\")\n",
    "])\n",
    "\n",
    "# 최신 LangChain 방식: RunnableSequence 활용\n",
    "chain = prompt_template | llm\n",
    "\n",
    "# 실행 예시\n",
    "question = \"파이썬은 무엇인가요?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0af4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
